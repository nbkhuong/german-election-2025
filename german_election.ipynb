{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import io\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.conf import SparkConf\n",
    "\n",
    "from retrieve_data import DataRetrieverOverAPI\n",
    "\n",
    "DAWUM_API_URL = \"https://api.dawum.de/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/02/13 21:57:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "                    .appName(\"Spark Basics\") \\\n",
    "                    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dawum_api = DataRetrieverOverAPI(DAWUM_API_URL)\n",
    "data = dawum_api.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': {'Shortcut': 'Bundestag', 'Name': 'Bundestag', 'Election': 'Bundestagswahl'}, '8': {'Shortcut': 'Mecklenburg-Vorpommern', 'Name': 'Landtag von Mecklenburg-Vorpommern', 'Election': 'Landtagswahl in Mecklenburg-Vorpommern'}, '16': {'Shortcut': 'Thüringen', 'Name': 'Thüringischer Landtag', 'Election': 'Landtagswahl in Thüringen'}, '6': {'Shortcut': 'Hamburg', 'Name': 'Hamburgische Bürgerschaft', 'Election': 'Bürgerschaftswahl in Hamburg'}, '4': {'Shortcut': 'Brandenburg', 'Name': 'Brandenburgischer Landtag', 'Election': 'Landtagswahl in Brandenburg'}, '15': {'Shortcut': 'Schleswig-Holstein', 'Name': 'Landtag von Schleswig-Holstein', 'Election': 'Landtagswahl in Schleswig-Holstein'}, '14': {'Shortcut': 'Sachsen-Anhalt', 'Name': 'Landtag von Sachsen-Anhalt', 'Election': 'Landtagswahl in Sachsen-Anhalt'}, '13': {'Shortcut': 'Sachsen', 'Name': 'Sächsischer Landtag', 'Election': 'Landtagswahl in Sachsen'}, '7': {'Shortcut': 'Hessen', 'Name': 'Hessischer Landtag', 'Election': 'Landtagswahl in Hessen'}, '10': {'Shortcut': 'Nordrhein-Westfalen (NRW)', 'Name': 'Landtag von Nordrhein-Westfalen', 'Election': 'Landtagswahl in Nordrhein-Westfalen (NRW)'}, '1': {'Shortcut': 'Baden-Württemberg', 'Name': 'Landtag von Baden-Württemberg', 'Election': 'Landtagswahl in Baden-Württemberg'}, '11': {'Shortcut': 'Rheinland-Pfalz', 'Name': 'Landtag von Rheinland-Pfalz', 'Election': 'Landtagswahl in Rheinland-Pfalz'}, '9': {'Shortcut': 'Niedersachsen', 'Name': 'Niedersächsischer Landtag', 'Election': 'Landtagswahl in Niedersachsen'}, '3': {'Shortcut': 'Berlin', 'Name': 'Berliner Abgeordnetenhaus', 'Election': 'Abgeordnetenhauswahl in Berlin'}, '2': {'Shortcut': 'Bayern', 'Name': 'Bayerischer Landtag', 'Election': 'Landtagswahl in Bayern'}, '12': {'Shortcut': 'Saarland', 'Name': 'Saarländischer Landtag', 'Election': 'Landtagswahl im Saarland'}, '17': {'Shortcut': 'Europäisches Parlament', 'Name': 'Europäisches Parlament', 'Election': 'Europawahl'}, '5': {'Shortcut': 'Bremen', 'Name': 'Bremische Bürgerschaft', 'Election': 'Bürgerschaftswahl in Bremen'}}\n"
     ]
    }
   ],
   "source": [
    "dawum_database = data['Database']\n",
    "dawum_parliaments = data['Parliaments']\n",
    "dawum_institutes = data['Institutes']\n",
    "dawum_taskers = data['Taskers']\n",
    "dawum_methods = data['Methods']\n",
    "dawum_parties = data['Parties']\n",
    "dawum_surveys = data['Surveys']\n",
    "\n",
    "print(dawum_parliaments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+---------+--------------------+----------------+--------------------+\n",
      "|              author|         last_update|publisher|        license_name|license_shortcut|        license_link|\n",
      "+--------------------+--------------------+---------+--------------------+----------------+--------------------+\n",
      "|Dipl.-Jur. Philip...|2025-02-13T20:48:...| dawum.de|ODC Open Database...|        ODC-ODbL|https://opendatac...|\n",
      "+--------------------+--------------------+---------+--------------------+----------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_database = spark.read.json(spark.sparkContext.parallelize([dawum_database]))\n",
    "df_database = df_database.withColumn(\"license_name\", F.col(\"License.Name\")) \\\n",
    "                    .withColumn(\"license_shortcut\", F.col(\"License.Shortcut\")) \\\n",
    "                    .withColumn(\"license_link\", F.col(\"License.Link\")) \\\n",
    "                    .drop(\"License\") \\\n",
    "                    .withColumnRenamed(\"Author\", \"author\") \\\n",
    "                    .withColumnRenamed(\"Last_Update\", \"last_update\") \\\n",
    "                    .withColumnRenamed(\"Publisher\", \"publisher\") \\\n",
    "                    \n",
    "df_database.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+--------------------+--------------------+\n",
      "|parliament_id|     parliament_name| parliament_shortcut| parliament_election|\n",
      "+-------------+--------------------+--------------------+--------------------+\n",
      "|            0|           Bundestag|           Bundestag|      Bundestagswahl|\n",
      "|            8|Landtag von Meckl...|Mecklenburg-Vorpo...|Landtagswahl in M...|\n",
      "|           16|Thüringischer Lan...|           Thüringen|Landtagswahl in T...|\n",
      "|            6|Hamburgische Bürg...|             Hamburg|Bürgerschaftswahl...|\n",
      "|            4|Brandenburgischer...|         Brandenburg|Landtagswahl in B...|\n",
      "|           15|Landtag von Schle...|  Schleswig-Holstein|Landtagswahl in S...|\n",
      "|           14|Landtag von Sachs...|      Sachsen-Anhalt|Landtagswahl in S...|\n",
      "|           13| Sächsischer Landtag|             Sachsen|Landtagswahl in S...|\n",
      "|            7|  Hessischer Landtag|              Hessen|Landtagswahl in H...|\n",
      "|           10|Landtag von Nordr...|Nordrhein-Westfal...|Landtagswahl in N...|\n",
      "|            1|Landtag von Baden...|   Baden-Württemberg|Landtagswahl in B...|\n",
      "|           11|Landtag von Rhein...|     Rheinland-Pfalz|Landtagswahl in R...|\n",
      "|            9|Niedersächsischer...|       Niedersachsen|Landtagswahl in N...|\n",
      "|            3|Berliner Abgeordn...|              Berlin|Abgeordnetenhausw...|\n",
      "|            2| Bayerischer Landtag|              Bayern|Landtagswahl in B...|\n",
      "|           12|Saarländischer La...|            Saarland|Landtagswahl im S...|\n",
      "|           17|Europäisches Parl...|Europäisches Parl...|          Europawahl|\n",
      "|            5|Bremische Bürgers...|              Bremen|Bürgerschaftswahl...|\n",
      "+-------------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rdd = spark.sparkContext.parallelize(dawum_parliaments.items())  # Parallelize the dictionary items\n",
    "\n",
    "df_parliaments = rdd.map(lambda x: (x[0], x[1]['Name'], x[1]['Shortcut'], x[1]['Election'])).toDF([\"parliament_id\", \"parliament_name\", \"parliament_shortcut\", \"parliament_election\"])\n",
    "\n",
    "df_parliaments.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+\n",
      "|institute_id|      institute_name|\n",
      "+------------+--------------------+\n",
      "|           1|     Infratest dimap|\n",
      "|          22|            pollytix|\n",
      "|          13|              YouGov|\n",
      "|           2|               Forsa|\n",
      "|           5|                INSA|\n",
      "|           4|                 GMS|\n",
      "|           6|Forschungsgruppe ...|\n",
      "|          17|               Ipsos|\n",
      "|          24|Institut Wahlkrei...|\n",
      "|           3|      Verian (Emnid)|\n",
      "|           7|Trend Research Ha...|\n",
      "|           9|          Allensbach|\n",
      "|          16|               Civey|\n",
      "|          25|          IFM Berlin|\n",
      "|          21|      Policy Matters|\n",
      "|          18| Universität Hamburg|\n",
      "|          15|         Mentefactum|\n",
      "|          20|            IM Field|\n",
      "|          12|              uniQma|\n",
      "|          23|           Conoscope|\n",
      "+------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rdd = spark.sparkContext.parallelize(dawum_institutes.items())  # Parallelize the dictionary items\n",
    "df_institutes = rdd.map(lambda x: (x[0], x[1][\"Name\"])).toDF([\"institute_id\", \"institute_name\"])\n",
    "df_institutes.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+\n",
      "|tasker_id|         tasker_name|\n",
      "+---------+--------------------+\n",
      "|       10|     ARD-Tagesthemen|\n",
      "|       67|            pollytix|\n",
      "|       43|              YouGov|\n",
      "|       63|          RTL / n-tv|\n",
      "|        4|                BILD|\n",
      "|        3|     BILD am Sonntag|\n",
      "|       38|      Ostsee-Zeitung|\n",
      "|        7|                 GMS|\n",
      "|        5|  ZDF-Politbarometer|\n",
      "|       13|               Ipsos|\n",
      "|       80|FUNKE Medien Thür...|\n",
      "|       39|                 NDR|\n",
      "|       97|Institut Wahlkrei...|\n",
      "|       64|               FOCUS|\n",
      "|      112|Märkische Allgeme...|\n",
      "|      120|Radio Hamburg / D...|\n",
      "|        6|Frankfurter Allge...|\n",
      "|       62|  Sächsische Zeitung|\n",
      "|      121|      Osthessen|News|\n",
      "|      100|  NRW-Tageszeitungen|\n",
      "+---------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rdd = spark.sparkContext.parallelize(dawum_taskers.items())\n",
    "df_taskers = rdd.map(lambda x: (x[0], x[1][\"Name\"])).toDF([\"tasker_id\", \"tasker_name\"])\n",
    "df_taskers.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------------+\n",
      "|method_id|     method_name|\n",
      "+---------+----------------+\n",
      "|        4|Telefon & Online|\n",
      "|        3|          Online|\n",
      "|        1|     Telefonisch|\n",
      "|        2|      Persönlich|\n",
      "|        0|       Unbekannt|\n",
      "+---------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rdd = spark.sparkContext.parallelize(dawum_methods.items())\n",
    "df_methods = rdd.map(lambda x: (x[0], x[1][\"Name\"])).toDF([\"method_id\", \"method_name\"])\n",
    "df_methods.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+----------------+\n",
      "|party_id|          party_name|  party_shortcut|\n",
      "+--------+--------------------+----------------+\n",
      "|       7|Alternative für D...|             AfD|\n",
      "|      11|   Bayernpartei e.V.|    Bayernpartei|\n",
      "|      14|Brandenburger Ver...|          BVB/FW|\n",
      "|       4|Bündnis 90/Die Gr...|           Grüne|\n",
      "|      23|Bündnis Sahra Wag...|             BSW|\n",
      "|      21|bunt.saar – sozia...|       bunt.saar|\n",
      "|      22|Bürger für Thüringen|            BfTh|\n",
      "|      16|       Bürger in Wut|             BIW|\n",
      "|       1|Christlich Demokr...|         CDU/CSU|\n",
      "|     101|Christlich Demokr...|             CDU|\n",
      "|     102|Christlich-Sozial...|             CSU|\n",
      "|       5|           Die Linke|           Linke|\n",
      "|      17|Familienpartei De...|         Familie|\n",
      "|       3|Freie Demokratisc...|             FDP|\n",
      "|       8|        Freie Wähler|    Freie Wähler|\n",
      "|       9|Nationaldemokrati...|             NPD|\n",
      "|      12|Ökologisch-Demokr...|             ÖDP|\n",
      "|      13|Partei für Arbeit...|      Die PARTEI|\n",
      "|      15|Partei Mensch Umw...|Tierschutzpartei|\n",
      "|       6|       Piratenpartei|         Piraten|\n",
      "|      24|Plus Brandenburg ...|Plus Brandenburg|\n",
      "|       2|Sozialdemokratisc...|             SPD|\n",
      "|      10|Südschleswigscher...|             SSW|\n",
      "|      18|    Volt Deutschland|            Volt|\n",
      "|      25|          WerteUnion|      WerteUnion|\n",
      "|       0|   sonstige Parteien|        Sonstige|\n",
      "+--------+--------------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rdd = spark.sparkContext.parallelize(dawum_parties.items())\n",
    "df_parties = rdd.map(lambda x: (x[0], x[1][\"Name\"], x[1][\"Shortcut\"])).toDF([\"party_id\", \"party_name\", \"party_shortcut\"])\n",
    "df_parties.show(df_parties.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+------------+---------+---------+--------+------------------------+-------------------+-----------------+---------------+---------------+\n",
      "|survey_id|parliament_id|institute_id|tasker_id|method_id|party_id|survey_result_by_percent|survey_publish_date|survey_start_date|survey_end_date|total_surveyees|\n",
      "+---------+-------------+------------+---------+---------+--------+------------------------+-------------------+-----------------+---------------+---------------+\n",
      "|     3751|            0|           1|       10|        4|       0|                       0|         2025-02-13|       2025-02-10|     2025-02-12|           1579|\n",
      "|     3751|            0|           1|       10|        4|      23|                       0|         2025-02-13|       2025-02-10|     2025-02-12|           1579|\n",
      "|     3751|            0|           1|       10|        4|       1|                      32|         2025-02-13|       2025-02-10|     2025-02-12|           1579|\n",
      "|     3751|            0|           1|       10|        4|       2|                      14|         2025-02-13|       2025-02-10|     2025-02-12|           1579|\n",
      "|     3751|            0|           1|       10|        4|       3|                       4|         2025-02-13|       2025-02-10|     2025-02-12|           1579|\n",
      "|     3751|            0|           1|       10|        4|       4|                      14|         2025-02-13|       2025-02-10|     2025-02-12|           1579|\n",
      "|     3751|            0|           1|       10|        4|       5|                       6|         2025-02-13|       2025-02-10|     2025-02-12|           1579|\n",
      "|     3751|            0|           1|       10|        4|       7|                      21|         2025-02-13|       2025-02-10|     2025-02-12|           1579|\n",
      "|     3750|            0|          22|       67|        3|       0|                       6|         2025-02-12|       2025-02-11|     2025-02-12|           1501|\n",
      "|     3750|            0|          22|       67|        3|      23|                       5|         2025-02-12|       2025-02-11|     2025-02-12|           1501|\n",
      "|     3750|            0|          22|       67|        3|       1|                      29|         2025-02-12|       2025-02-11|     2025-02-12|           1501|\n",
      "|     3750|            0|          22|       67|        3|       2|                      17|         2025-02-12|       2025-02-11|     2025-02-12|           1501|\n",
      "|     3750|            0|          22|       67|        3|       3|                       4|         2025-02-12|       2025-02-11|     2025-02-12|           1501|\n",
      "|     3750|            0|          22|       67|        3|       4|                      14|         2025-02-12|       2025-02-11|     2025-02-12|           1501|\n",
      "|     3750|            0|          22|       67|        3|       5|                       6|         2025-02-12|       2025-02-11|     2025-02-12|           1501|\n",
      "|     3750|            0|          22|       67|        3|       7|                      19|         2025-02-12|       2025-02-11|     2025-02-12|           1501|\n",
      "|     3749|            0|          13|       43|        3|       0|                       6|         2025-02-12|       2025-02-07|     2025-02-10|           2083|\n",
      "|     3749|            0|          13|       43|        3|      23|                       5|         2025-02-12|       2025-02-07|     2025-02-10|           2083|\n",
      "|     3749|            0|          13|       43|        3|       1|                      29|         2025-02-12|       2025-02-07|     2025-02-10|           2083|\n",
      "|     3749|            0|          13|       43|        3|       2|                      16|         2025-02-12|       2025-02-07|     2025-02-10|           2083|\n",
      "+---------+-------------+------------+---------+---------+--------+------------------------+-------------------+-----------------+---------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rdd = spark.sparkContext.parallelize(dawum_surveys.items())\n",
    "df_surveys = rdd.map(lambda x: (x[0], \n",
    "                                x[1][\"Parliament_ID\"],\n",
    "                                x[1][\"Institute_ID\"],\n",
    "                                x[1][\"Tasker_ID\"],\n",
    "                                x[1][\"Method_ID\"],\n",
    "                                x[1][\"Date\"], \n",
    "                                x[1][\"Survey_Period\"][\"Date_Start\"], \n",
    "                                x[1][\"Survey_Period\"][\"Date_End\"],\n",
    "                                x[1][\"Surveyed_Persons\"],\n",
    "                                x[1][\"Results\"]\n",
    "                                )) \\\n",
    "                        .toDF([\"survey_id\", \n",
    "                               \"parliament_id\",\n",
    "                               \"institute_id\",\n",
    "                               \"tasker_id\",\n",
    "                               \"method_id\",\n",
    "                               \"survey_publish_date\",\n",
    "                               \"survey_start_date\", \n",
    "                               \"survey_end_date\",\n",
    "                               \"total_surveyees\",\n",
    "                               \"results\"])\n",
    "\n",
    "df_surveys = df_surveys.select(F.col(\"survey_id\"), \n",
    "                               F.col(\"parliament_id\"),\n",
    "                               F.col(\"institute_id\"),\n",
    "                               F.col(\"tasker_id\"),\n",
    "                               F.col(\"method_id\"),\n",
    "                               F.explode(df_surveys.results).alias(\"party_id\", \"survey_result_by_percent\"),\n",
    "                               F.col(\"survey_publish_date\"),\n",
    "                               F.col(\"survey_start_date\"), \n",
    "                               F.col(\"survey_end_date\"),\n",
    "                               F.col(\"total_surveyees\") \n",
    "                               )\n",
    "\n",
    "df_surveys = df_surveys.fillna({\"survey_result_by_percent\": 0})\n",
    "df_surveys.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
